{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "950cf5a1",
      "metadata": {
        "id": "950cf5a1"
      },
      "source": [
        "# Conectar con LLMs locales y remotos\n",
        "\n",
        "**Curso: Inteligencia Artificial Generativa ‚Äì Conexi√≥n con Modelos de Lenguaje**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3a4d00b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a4d00b5",
        "outputId": "a285f598-c846-4073-bafb-260d2fa28408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.0)\n",
            "Requirement already satisfied: dotenv in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.9.9)\n",
            "Requirement already satisfied: gradio in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.49.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.6.2.post1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dotenv) (1.1.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.118.0)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydub in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.13.3->gradio) (2025.9.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\christian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install openai dotenv gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "30679223",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30679223",
        "outputId": "46c0abd1-b33e-4976-eb61-31e6df4f2685"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "13b736c8",
      "metadata": {
        "id": "13b736c8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "open_router_api_key = os.getenv('OPEN_ROUTER_API_KEY')\n",
        "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
        "groq_api_key = os.getenv('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fAW0PWUYU9rr",
      "metadata": {
        "id": "fAW0PWUYU9rr"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1bb8a4b7",
      "metadata": {
        "id": "1bb8a4b7"
      },
      "source": [
        "# OpenRouterAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8aa2de06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aa2de06",
        "outputId": "99181382-4a3d-4bff-a17d-1385aecdf07f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# ¬øQu√© es la AI (Inteligencia Artificial)?\n",
            "\n",
            "La **Inteligencia Artificial (AI o IA)** es una rama de la inform√°tica que busca crear sistemas capaces de realizar tareas que normalmente requieren inteligencia humana.\n",
            "\n",
            "## Capacidades principales:\n",
            "\n",
            "- **Aprendizaje**: Mejorar con la experiencia\n",
            "- **Razonamiento**: Resolver problemas y tomar decisiones\n",
            "- **Percepci√≥n**: Reconocer patrones, im√°genes, voz\n",
            "- **Comprensi√≥n del lenguaje**: Entender y generar texto\n",
            "- **Adaptaci√≥n**: Ajustarse a nuevas situaciones\n",
            "\n",
            "## Ejemplos cotidianos:\n",
            "\n",
            "- Asistentes virtuales (Siri, Alexa, Google Assistant)\n",
            "- Recomendaciones en Netflix o Spotify\n",
            "- Reconocimiento facial en smartphones\n",
            "- Traducci√≥n autom√°tica\n",
            "- Veh√≠culos aut√≥nomos\n",
            "- Chatbots como yo\n",
            "\n",
            "## Tipos principales:\n",
            "\n",
            "1. **IA d√©bil o estrecha**: Dise√±ada para tareas espec√≠ficas (la que existe actualmente)\n",
            "2. **IA general**: Hipot√©tica IA con capacidades humanas completas (a√∫n no existe)\n",
            "\n",
            "La AI moderna funciona principalmente mediante **machine learning** (aprendizaje autom√°tico), donde los sistemas aprenden de grandes cantidades de datos en lugar de seguir instrucciones programadas expl√≠citamente.\n",
            "\n",
            "¬øTe gustar√≠a saber m√°s sobre alg√∫n aspecto espec√≠fico de la IA?\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "open_router_ai = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=open_router_api_key,\n",
        ")\n",
        "completion = open_router_ai.chat.completions.create(\n",
        "  extra_headers={\n",
        "    \"HTTP-Referer\": \"MI PAGINA o APP\",\n",
        "    \"X-Title\": \"ANDY CODE\",\n",
        "  },\n",
        "  model=\"anthropic/claude-sonnet-4.5\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Que es AI\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d4955c",
      "metadata": {
        "id": "a2d4955c"
      },
      "source": [
        "# Google AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "74069e85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "74069e85",
        "outputId": "a95483b9-7e38-426e-a1a2-c02da1c79c6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'**AI** son las siglas de **Inteligencia Artificial** (del ingl√©s Artificial Intelligence).\\n\\nEn su esencia, la AI se refiere a la capacidad de las m√°quinas para **simular la inteligencia humana**. Esto significa que las computadoras o sistemas pueden realizar tareas que normalmente requieren pensamiento, aprendizaje, resoluci√≥n de problemas y toma de decisiones por parte de un ser humano.\\n\\n**¬øQu√© busca la AI?**\\n\\nEl objetivo principal de la AI es crear sistemas que puedan:\\n\\n1.  **Aprender:** Adquirir conocimientos y habilidades a partir de datos y experiencia, sin ser programados expl√≠citamente para cada situaci√≥n. (Aqu√≠ es donde entra el Machine Learning).\\n2.  **Razonar:** Utilizar la l√≥gica para llegar a conclusiones a partir de la informaci√≥n disponible.\\n3.  **Resolver problemas:** Identificar y encontrar soluciones a desaf√≠os espec√≠ficos.\\n4.  **Percepci√≥n:** Interpretar informaci√≥n del entorno a trav√©s de sensores (como c√°maras o micr√≥fonos), similar a c√≥mo los humanos usan sus sentidos.\\n5.  **Comprender el lenguaje natural:** Interactuar con los humanos usando el lenguaje que hablamos, no solo c√≥digo.\\n6.  **Reconocer patrones:** Identificar tendencias y regularidades en grandes conjuntos de datos.\\n\\n**Tipos de AI:**\\n\\nCom√∫nmente se distinguen dos tipos principales:\\n\\n1.  **AI D√©bil (o AI Estrecha/ANI - Artificial Narrow Intelligence):** Es el tipo de AI que existe hoy en d√≠a. Est√° dise√±ada para realizar una **tarea espec√≠fica** muy bien, pero no tiene una inteligencia general comparable a la humana.\\n    *   **Ejemplos:** Asistentes de voz como Siri o Alexa, sistemas de recomendaci√≥n de Netflix, coches aut√≥nomos (para la tarea de conducir), filtros de spam, programas de ajedrez.\\n\\n2.  **AI Fuerte (o AI General/AGI - Artificial General Intelligence):** Es una AI hipot√©tica que podr√≠a comprender, aprender y aplicar la inteligencia a **cualquier tarea intelectual** que un humano pueda realizar. Tendr√≠a conciencia, razonamiento y la capacidad de aprender de forma generalizada. A√∫n no existe y es un tema de investigaci√≥n y debate.\\n\\n**Tecnolog√≠as clave dentro de la AI:**\\n\\n*   **Machine Learning (Aprendizaje Autom√°tico):** Es una rama de la AI que permite a las m√°quinas aprender de los datos sin ser programadas expl√≠citamente.\\n*   **Deep Learning (Aprendizaje Profundo):** Una subcategor√≠a del Machine Learning que utiliza redes neuronales artificiales con m√∫ltiples capas para modelar abstracciones de alto nivel en los datos (ej. reconocimiento de im√°genes o voz).\\n*   **Procesamiento del Lenguaje Natural (PLN/NLP):** Permite a las m√°quinas entender, interpretar y generar lenguaje humano.\\n*   **Visi√≥n por Computadora:** Habilita a las m√°quinas para \"ver\" e interpretar im√°genes y videos.\\n*   **Rob√≥tica:** Integraci√≥n de la AI en sistemas rob√≥ticos f√≠sicos.\\n\\n**En resumen:**\\n\\nLa AI es un campo amplio y en constante evoluci√≥n que busca dotar a las m√°quinas con capacidades inteligentes, emulando o incluso superando algunas habilidades cognitivas humanas. Est√° transformando r√°pidamente casi todos los aspectos de nuestra vida y trabajo.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gemini = OpenAI(api_key=gemini_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
        "model_name = \"gemini-2.5-flash\"\n",
        "\n",
        "response = gemini.chat.completions.create(model=model_name, messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Que es AI\"\n",
        "    }\n",
        "  ])\n",
        "answer = response.choices[0].message.content\n",
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abad7c2d",
      "metadata": {
        "id": "abad7c2d"
      },
      "source": [
        "# Ollama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "822aee6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "822aee6d",
        "outputId": "04d56a63-d914-41c5-dfcd-3d62541518f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'La pregunta definitiva en el siglo XXI!\\n\\nAI (Inteligencia Artificial) se refiere al desarrollo de sistemas y programas que pueden imitar habilidades humanas, como el pensamiento, la toma de decisiones o la percepci√≥n. Estos sistemas utilizan algoritmos inform√°ticos y datos para simular inteligencia, aprendizaje y adaptaci√≥n.\\n\\nLa IA se basa en various disciplines, incluyendo:\\n\\n1. **Inform√°tica**: La creaci√≥n de programas que pueden procesar informaci√≥n, hacer c√°lculos y tomar decisiones.\\n2. **Psicolog√≠a**: El estudio del comportamiento humano y la motivaci√≥n para crear sistemas que pueden imitar la forma en que los seres humanos piensan y se comportan.\\n3. **Econom√≠a**: La comprensi√≥n de c√≥mo las instituciones y los mercados funcionan y c√≥mo los sistemas puede influir en ellos.\\n4. **Biolog√≠a**: El estudio del cerebro humano y como funciona para crear sistemas que pueden imitar la forma en que el cerebro humano procesa informaci√≥n.\\n\\nLa IA se ha dividido en diferentes √°reas, incluyendo:\\n\\n1. **IA d√©bil** (Weak AI): Sistemas que pueden realizar tareas espec√≠ficas, pero no son capaces de aprender o adaptarse.\\n2. **IA fuerte** (Strong AI): Sistemas que pueden realizar cualquier tarea que un humano pueda hacer, y est√°n en camino a la autonom√≠a.\\n3. **IA de nivel medio** (Mid-level AI): Sistemas que combinan habilidades d√©biles e inteligencia artificial para resolver problemas complejos.\\n\\nLas aplicaciones de la IA incluyen:\\n\\n1. **Asistente virtual**: Sistemas como Siri, Alexa o Google Assistant que pueden interactuar con los usuarios y realizar tareas para ellos.\\n2. **Machine learning**: El desarrollo de algoritmos que pueden aprender a partir de datos y mejorar sus habilidades autom√°ticamente.\\n3. **Robotica**: La creaci√≥n de robots que pueden interactuar con el entorno y realizar tareas f√≠sicas.\\n4. **An√°lisis de im√°genes y audio**: Sistemas que pueden analizar y procesar informaci√≥n visual o auditiva.\\n\\nLa IA sigue evolucionando a un ritmo r√°pido, y se cree que tendr√° un impacto significativo en muchos aspectos de nuestra vida, incluyendo la industria, la educaci√≥n, la salud y la sociedad en general.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
        "model_name = \"llama3\"\n",
        "\n",
        "response = ollama.chat.completions.create(model=model_name, messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Que es AI\"\n",
        "    }\n",
        "  ])\n",
        "answer = response.choices[0].message.content\n",
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ca79f71",
      "metadata": {
        "id": "4ca79f71"
      },
      "source": [
        "# Grog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0b30c7f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "0b30c7f7",
        "outputId": "02af2d1f-7d61-48d6-ecfe-b742c501c49d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'**Introducci√≥n a la Inteligencia Artificial (IA)**\\n\\nLa Inteligencia Artificial (IA), tambi√©n conocida como Artificial Intelligence (AI) en ingl√©s, se refiere a la creaci√≥n de sistemas inform√°ticos capaces de realizar tareas que normalmente requieren inteligencia humana, como la comprensi√≥n del lenguaje, el aprendizaje, la resoluci√≥n de problemas y la toma de decisiones.\\n\\n**Or√≠genes y evoluci√≥n**\\n\\nLa IA tiene sus ra√≠ces en la d√©cada de 1950, cuando los investigadores comenzaron a explorar la posibilidad de crear m√°quinas que pudieran pensar y aprender como los seres humanos. Desde entonces, la IA ha evolucionado significativamente, con avances en √°reas como la inform√°tica, la estad√≠stica y la ingenier√≠a.\\n\\n**Tipos de IA**\\n\\nExisten varios tipos de IA, que se pueden clasificar en:\\n\\n1. **IA d√©bil**: se enfoca en la resoluci√≥n de problemas espec√≠ficos y no tiene la capacidad de razonar o aprender de manera general.\\n2. **IA fuerte**: se enfoca en la creaci√≥n de sistemas que puedan razonar y aprender de manera general, similar a la inteligencia humana.\\n3. **IA superinteligente**: se refiere a sistemas que superan significativamente la inteligencia humana en todos los aspectos.\\n\\n**T√©cnicas y herramientas**\\n\\nLa IA utiliza una variedad de t√©cnicas y herramientas, incluyendo:\\n\\n1. **Redes neuronales**: inspiradas en la estructura y funci√≥n del cerebro humano, estas redes pueden aprender y adaptarse a nuevas situaciones.\\n2. **Aprendizaje autom√°tico**: permite a los sistemas aprender de datos y mejorar su rendimiento con el tiempo.\\n3. **Procesamiento del lenguaje natural**: permite a los sistemas comprender y generar lenguaje humano.\\n\\n**Aplicaciones**\\n\\nLa IA tiene una amplia gama de aplicaciones en √°reas como:\\n\\n1. **Asistentes virtuales**: como Siri, Alexa y Google Assistant.\\n2. **Reconocimiento de im√°genes**: en aplicaciones como la detecci√≥n de objetos y la identificaci√≥n de personas.\\n3. **Automatizaci√≥n**: en la industria y la log√≠stica.\\n4. **Salud**: en la diagn√≥stica y el tratamiento de enfermedades.\\n\\n**Conclusi√≥n**\\n\\nLa Inteligencia Artificial es un campo en constante evoluci√≥n, con un enorme potencial para transformar la forma en que vivimos y trabajamos. A medida que la IA contin√∫a avanzando, es importante considerar sus implicaciones √©ticas y sociales, y garantizar que se utilice de manera responsable y beneficiosa para la sociedad.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "groq_api_key = os.getenv('GROQ_API_KEY')\n",
        "grog_ai = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
        "model_name = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "response = grog_ai.chat.completions.create(model=model_name, messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Que es AI\"\n",
        "    }\n",
        "  ])\n",
        "answer = response.choices[0].message.content\n",
        "answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed93c893",
      "metadata": {
        "id": "ed93c893"
      },
      "source": [
        "https://colab.research.google.com/drive/1N0DnlJvVPVAammqPi6XRksbQ67qUgLWD#scrollTo=VF9EZrr_nZ4F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8f85c8bd",
      "metadata": {
        "id": "8f85c8bd"
      },
      "outputs": [],
      "source": [
        "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
        "model_name = \"llama3\"\n",
        "\n",
        "def chat(message, history):\n",
        "    try:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"Eres un asistente de IA que responde preguntas y ayuda con tareas.\"}\n",
        "        ]\n",
        "\n",
        "        for msg in history:\n",
        "            if msg[\"role\"] == \"user\":\n",
        "                messages.append({\"role\": \"user\", \"content\": msg[\"content\"]})\n",
        "            elif msg[\"role\"] == \"assistant\":\n",
        "                messages.append({\"role\": \"assistant\", \"content\": msg[\"content\"]})\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        resp = ollama.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=messages,\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return f\"Error: {e}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0e51bfca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "0e51bfca",
        "outputId": "c66eeea7-28b8-4fea-bbfc-df5bed784b9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Christian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\Christian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7861\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "clients = {\n",
        "    \"Llama3 (Ollama)\": OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\"),\n",
        "    \"OpenRouter\": OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=open_router_api_key),\n",
        "    \"Gemini\": OpenAI(base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\", api_key=gemini_api_key),\n",
        "    \"Groq\": OpenAI(base_url=\"https://api.groq.com/openai/v1\", api_key=groq_api_key),\n",
        "}\n",
        "\n",
        "default_models = {\n",
        "    \"Llama3 (Ollama)\": \"llama3\",\n",
        "    \"OpenRouter\": \"anthropic/claude-sonnet-4.5\",\n",
        "    \"Gemini\": \"gemini-2.5-flash\",\n",
        "    \"Groq\": \"llama-3.3-70b-versatile\",\n",
        "}\n",
        "\n",
        "# --- Funci√≥n principal de chat ---\n",
        "def chat(message, history, selected_model):\n",
        "    # Convertir historial de Gradio a formato OpenAI\n",
        "    messages = []\n",
        "    for human, bot in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": human})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": bot})\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    # Cliente y modelo seg√∫n selecci√≥n\n",
        "    client = clients[selected_model]\n",
        "    model_name = default_models[selected_model]\n",
        "\n",
        "    # Llamada al modelo\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=messages\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# --- Interfaz con selector ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### ü§ñ Chat Multi-Modelo (Ollama, Gemini, Groq, OpenRouter)\")\n",
        "\n",
        "    model_choice = gr.Dropdown(\n",
        "        choices=list(clients.keys()),\n",
        "        value=\"Llama3 (Ollama)\",\n",
        "        label=\"Selecciona el modelo\"\n",
        "    )\n",
        "\n",
        "    chat_ui = gr.ChatInterface(\n",
        "        fn=chat,\n",
        "        additional_inputs=[model_choice],\n",
        "        title=\"Chat MLOps\",\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f1de9ead",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7862\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ===============================================\n",
        "# Switchable LLM App con Gradio\n",
        "# ===============================================\n",
        "import time\n",
        "\n",
        "# --- Configura tus claves (pon tus tokens aqu√≠) ---\n",
        "OPENROUTER_API_KEY = open_router_api_key\n",
        "GEMINI_API_KEY = gemini_api_key\n",
        "GROQ_API_KEY = groq_api_key\n",
        "\n",
        "# --- Configuraci√≥n de proveedores ---\n",
        "providers = {\n",
        "    \"Ollama\": {\n",
        "        \"client\": OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\"),\n",
        "        \"models\": [\"llama3\"]\n",
        "    },\n",
        "    \"OpenRouter\": {\n",
        "        \"client\": OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=OPENROUTER_API_KEY),\n",
        "        \"models\": [\"anthropic/claude-sonnet-4.5\", \"mistralai/mixtral-8x7b\"]\n",
        "    },\n",
        "    \"Gemini\": {\n",
        "        \"client\": OpenAI(base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\", api_key=GEMINI_API_KEY),\n",
        "        \"models\": [\"gemini-2.5-flash\", \"gemini-2.5-pro\"]\n",
        "    },\n",
        "    \"Groq\": {\n",
        "        \"client\": OpenAI(base_url=\"https://api.groq.com/openai/v1\", api_key=GROQ_API_KEY),\n",
        "        \"models\": [\"llama-3.3-70b-versatile\", \"mixtral-8x7b\"]\n",
        "    },\n",
        "}\n",
        "\n",
        "# --- Funci√≥n principal ---\n",
        "def process_text(provider, task, model, input_text,archivo):\n",
        "    if archivo is not None:\n",
        "        try:\n",
        "            with open(archivo.name, \"r\", encoding=\"utf-8\") as f:\n",
        "                input_text = f.read()\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error leyendo el archivo: {e}\", None, None, None\n",
        "    \n",
        "    if not input_text.strip():\n",
        "        return \"‚ö†Ô∏è Ingresa un texto para procesar.\", None, None, None\n",
        "\n",
        "    client = providers[provider][\"client\"]\n",
        "\n",
        "    prompt = \"\"\n",
        "    # Prompt seg√∫n tarea\n",
        "    if task == \"Traducci√≥n EN‚ÜíES\":\n",
        "        prompt = f\"Traduce el siguiente texto del ingl√©s al espa√±ol:\\n\\n{input_text}\"\n",
        "    elif task == \"Resumen\":\n",
        "        prompt = f\"Resume el siguiente texto de manera breve y clara:\\n\\n{input_text}\"\n",
        "    elif task == \"An√°lisis de sentimiento\":\n",
        "        prompt = (\n",
        "            f\"Analiza el sentimiento del siguiente texto. \"\n",
        "            f\"Responde si es positivo, negativo o neutral, y explica brevemente:\\n\\n{input_text}\"\n",
        "        )\n",
        "    else:\n",
        "        return \"‚ùå Tarea no reconocida.\", None, None, None\n",
        "\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "\n",
        "        output_text = response.choices[0].message.content.strip()\n",
        "        elapsed = round(time.time() - start_time, 2)\n",
        "\n",
        "        return (\n",
        "            output_text,\n",
        "            f\"{elapsed} s\",\n",
        "            len(input_text.split()),\n",
        "            len(output_text.split())\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\", None, None, None\n",
        "\n",
        "\n",
        "# --- Interfaz Gradio ---\n",
        "with gr.Blocks(title=\"Switchable LLM App\") as demo:\n",
        "    gr.Markdown(\"# ü§ñ Switchable LLM App con Gradio\")\n",
        "    gr.Markdown(\"Selecciona el **proveedor**, el **modelo** y la **tarea** que deseas ejecutar.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        provider = gr.Dropdown(label=\"Proveedor\", choices=list(providers.keys()), value=\"Ollama\")\n",
        "        task = gr.Dropdown(\n",
        "            label=\"Tarea\",\n",
        "            choices=[\"Traducci√≥n EN‚ÜíES\", \"Resumen\", \"An√°lisis de sentimiento\"],\n",
        "            value=\"Traducci√≥n EN‚ÜíES\"\n",
        "        )\n",
        "\n",
        "\n",
        "    model = gr.Dropdown(label=\"Modelo\", choices=providers[\"Ollama\"][\"models\"], value=\"llama3\")\n",
        "\n",
        "    # Actualiza modelos seg√∫n el proveedor seleccionado\n",
        "    def update_models(selected_provider):\n",
        "        return gr.update(choices=providers[selected_provider][\"models\"], value=providers[selected_provider][\"models\"][0])\n",
        "\n",
        "    provider.change(update_models, inputs=provider, outputs=model)\n",
        "\n",
        "    input_text = gr.Textbox(lines=8, label=\"Texto de entrada\")\n",
        "    archivo_input = gr.File(label=\"Sube un archivo .txt (opcional)\", file_types=[\".txt\"])\n",
        "    output_text = gr.Textbox(lines=8, label=\"Resultado\", interactive=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        time_box = gr.Textbox(label=\"‚è±Ô∏è Tiempo de inferencia\", interactive=False)\n",
        "        in_len = gr.Textbox(label=\"üî§ Palabras input\", interactive=False)\n",
        "        out_len = gr.Textbox(label=\"üí¨ Palabras output\", interactive=False)\n",
        "\n",
        "    run_button = gr.Button(\"üöÄ Procesar\")\n",
        "\n",
        "    run_button.click(\n",
        "        fn=process_text,\n",
        "        inputs=[provider, task, model, input_text, archivo_input],\n",
        "        outputs=[output_text, time_box, in_len, out_len]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
